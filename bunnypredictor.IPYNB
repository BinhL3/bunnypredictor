{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS383 Assignment 2 - Classification\n",
    "\n",
    "Name: Binh Le - Section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['father_white', 'father_grey', 'father_black', 'father_orange', 'father_brown', 'father_lilac', 'father_frosty', 'father_tricolor', 'father_broken', 'father_harlequin', 'father_vienna', 'father_eye_brown', 'father_eye_blue', 'mother_white', 'mother_grey', 'mother_black', 'mother_orange', 'mother_brown', 'mother_lilac', 'mother_vienna', 'mother_solid', 'mother_broken', 'mother_harlequin', 'mother_eye_brown', 'mother_eye_blue', 'child_contains_black']\n",
      "Sample row: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "Sample row: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "Data shape: (30, 26)\n",
      "X shape: (30, 25) Y shape: (30,)\n",
      "Y values: [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 1.]\n",
      "Y distribution: [16 14]\n",
      "Iteration 0, Loss: 1.146551095610797\n",
      "Iteration 100, Loss: 0.9907861747042485\n",
      "Iteration 200, Loss: 0.8610298533955643\n",
      "Iteration 300, Loss: 0.756148557346194\n",
      "Iteration 400, Loss: 0.67334473903625\n",
      "Iteration 500, Loss: 0.609043588204835\n",
      "Iteration 600, Loss: 0.5596262997918164\n",
      "Iteration 700, Loss: 0.5218514369191208\n",
      "Iteration 800, Loss: 0.49301765222803134\n",
      "Iteration 900, Loss: 0.4709719466644632\n",
      "Iteration 1000, Loss: 0.4540460687538026\n",
      "Iteration 1100, Loss: 0.4409702707889539\n",
      "Iteration 1200, Loss: 0.43078877587224634\n",
      "Iteration 1300, Loss: 0.42278676511369473\n",
      "Iteration 1400, Loss: 0.41643131312938175\n",
      "Iteration 1500, Loss: 0.4113254069168142\n",
      "Iteration 1600, Loss: 0.40717299273227847\n",
      "Iteration 1700, Loss: 0.40375280066172536\n",
      "Iteration 1800, Loss: 0.4008989206302851\n",
      "Iteration 1900, Loss: 0.3984864617303943\n",
      "Iteration 2000, Loss: 0.396420988426988\n",
      "Iteration 2100, Loss: 0.39463074087635197\n",
      "Iteration 2200, Loss: 0.3930608989676701\n",
      "Iteration 2300, Loss: 0.3916693442123714\n",
      "Iteration 2400, Loss: 0.3904235196668008\n",
      "Iteration 2500, Loss: 0.3892980959991819\n",
      "Iteration 2600, Loss: 0.38827323079366705\n",
      "Iteration 2700, Loss: 0.3873332656787313\n",
      "Iteration 2800, Loss: 0.38646574762334635\n",
      "Iteration 2900, Loss: 0.385660691063752\n",
      "Test probabilities:\n",
      "Sample 0: 0.2555, Actual: 1.0\n",
      "Sample 1: 0.9904, Actual: 1.0\n",
      "Sample 2: 0.0493, Actual: 0.0\n",
      "Sample 3: 0.0493, Actual: 0.0\n",
      "Sample 4: 0.9904, Actual: 1.0\n",
      "Sample 5: 0.0369, Actual: 1.0\n",
      "Sample 6: 0.9904, Actual: 1.0\n",
      "Sample 7: 0.0493, Actual: 0.0\n",
      "Sample 8: 0.8806, Actual: 1.0\n",
      "TP: 4 FN: 3 FP: 0 TN: 2\n",
      "Precision:  1.0\n",
      "Recall:  0.5714285714285714\n",
      "F_measure:  0.7272727272727273\n",
      "Acurracy:  0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Read data\n",
    "data = []\n",
    "with open('bunnypredictor.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    headers = next(reader)\n",
    "    print(\"Headers:\", headers)\n",
    "    for i, row in enumerate(reader):\n",
    "        new_row = [float(i) for i in row]\n",
    "        data.append(new_row)\n",
    "        if i < 2:\n",
    "            print(\"Sample row:\", new_row)\n",
    "\n",
    "data = np.array(data)\n",
    "print(\"Data shape:\", data.shape)\n",
    "\n",
    "X = data[:, :-1]  # 20 features\n",
    "Y = data[:, -1]   # 21st column as child_has_gray\n",
    "print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)\n",
    "print(\"Y values:\", Y)\n",
    "print(\"Y distribution:\", np.bincount(Y.astype(int)))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=21, test_size=9)\n",
    "\n",
    "# Standardize\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0, ddof=1)\n",
    "std[std == 0] = 1\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Add bias\n",
    "X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test = np.insert(X_test, 0, 1, axis=1)\n",
    "\n",
    "# Initialize Theta\n",
    "Theta = np.random.uniform(-1, 1, size=X_train.shape[1])\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Gradient Descent\n",
    "learning_rate = 0.001  # Increased\n",
    "prev_loss = float('inf')\n",
    "for i in range(3000):  # Increased iterations\n",
    "    cur_loss = 0\n",
    "    for j in range(len(X_train)):\n",
    "        y_pred = sigmoid(X_train[j] @ Theta)\n",
    "        cur_loss += - (y_train[j] * np.log(y_pred + 1e-15) + (1 - y_train[j]) * np.log(1 - y_pred + 1e-15))\n",
    "    cur_loss /= len(X_train)\n",
    "\n",
    "    if abs(cur_loss - prev_loss) < 2**(-23):\n",
    "        print(f\"Converged at iteration {i}\")\n",
    "        break\n",
    "    prev_loss = cur_loss\n",
    "\n",
    "    y_pred = sigmoid(X_train @ Theta)\n",
    "    Theta -= (learning_rate / len(X_train)) * X_train.T @ (y_pred - y_train)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}, Loss: {cur_loss}\")\n",
    "\n",
    "# Predict with probabilities\n",
    "print(\"Test probabilities:\")\n",
    "for i in range(len(X_test)):\n",
    "    y_pred = sigmoid(X_test[i] @ Theta)\n",
    "    print(f\"Sample {i}: {y_pred:.4f}, Actual: {y_test[i]}\")\n",
    "\n",
    "threshold = 0.3  # Adjusted threshold\n",
    "y_test_result = []\n",
    "for i in range(len(X_test)):\n",
    "    y_pred = sigmoid(X_test[i] @ Theta)\n",
    "    y_test_result.append(1 if y_pred >= threshold else 0)\n",
    "\n",
    "# 10. Computes the following statistics using the testing data results:\n",
    "TP, FN, FP, TN = 0, 0, 0, 0\n",
    "for i in range(len(y_test_result)):\n",
    "    if y_test_result[i] == 1: # predicted positive\n",
    "        if y_test_result[i] == y_test[i]: # positive examples\n",
    "            TP += 1\n",
    "        else: # negative examples\n",
    "            FP += 1\n",
    "    else: # predicted negative\n",
    "        if y_test_result[i] == y_test[i]: # positive examples\n",
    "            FN += 1\n",
    "        else: # negative examples\n",
    "            TN += 1\n",
    "    \n",
    "print(\"TP:\", TP,\"FN:\", FN, \"FP:\", FP, \"TN:\", TN)\n",
    "# (a) Precision:\n",
    "precision = TP/(TP + FP) \n",
    "print(\"Precision: \", precision)\n",
    "# (b) Recall:\n",
    "recall = TP/(TP+FN)\n",
    "print(\"Recall: \", recall)\n",
    "# (c) F-measure:\n",
    "f_measure = 2*precision*recall/(precision + recall)\n",
    "print(\"F_measure: \",f_measure)\n",
    "# (d) Accuracy:\n",
    "accuracy = 0\n",
    "for i in range(len(y_test_result)):\n",
    "    if y_test_result[i] == y_test[i]:\n",
    "        accuracy += 1\n",
    "accuracy /= len(y_test)\n",
    "print(\"Acurracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
